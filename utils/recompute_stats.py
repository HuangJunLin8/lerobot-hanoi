import argparse
import json
import os
from pathlib import Path

from lerobot.common.datasets.lerobot_dataset import LeRobotDataset
from lerobot.common.datasets.utils import EPISODES_STATS_PATH, INFO_PATH, EPISODES_PATH, load_stats, write_info
from lerobot.common.datasets.v21.convert_stats import convert_stats, check_aggregate_stats


def remove_old_stats(dataset):
    """åˆ é™¤æ—§ episodes_stats.jsonl æ–‡ä»¶"""
    stats_path = dataset.root / EPISODES_STATS_PATH
    if stats_path.exists():
        stats_path.unlink()
        print("ğŸ§¹ å·²åˆ é™¤æ—§ episodes_stats.jsonl")


def generate_new_stats(dataset, num_workers):
    """é‡æ–°ç”Ÿæˆ episodes_stats.jsonl æ–‡ä»¶"""
    convert_stats(dataset, num_workers=num_workers)
    print("âœ… æ–°ç»Ÿè®¡ä¿¡æ¯å·²ç”Ÿæˆï¼šepisodes_stats.jsonl")


def get_total_frames(episodes_path):
    """è®¡ç®—æ‰€æœ‰ episodes çš„æ€»å¸§æ•°"""
    total_frames = 0
    if episodes_path.exists():
        with open(episodes_path, "r") as f:
            for line in f:
                episode = json.loads(line)
                total_frames += episode.get("length", 0)
    return total_frames


def get_total_episodes(episodes_path):
    """è®¡ç®— episodes æ•°é‡"""
    if episodes_path.exists():
        with open(episodes_path, "r") as f:
            return sum(1 for _ in f)
    return 0


def get_total_videos(videos_path):
    """ç»Ÿè®¡ videos ç›®å½•ä¸‹æ‰€æœ‰è§†é¢‘æ•°é‡"""
    return sum(len(files) for _, _, files in os.walk(videos_path) if files)


def update_info_json(basePath, total_frames, total_episodes, total_videos):
    """æ›´æ–° info.json æ–‡ä»¶"""
    info_path = basePath / INFO_PATH
    if info_path.exists():
        with open(info_path, "r") as f:
            info_data = json.load(f)
    else:
        info_data = {}

    info_data.update({
        "total_frames": total_frames,
        "total_episodes": total_episodes,
        "total_videos": total_videos,
    })

    write_info(info_data, basePath)
    print(f"ğŸ“ å·²æ›´æ–° info.json: total_frames={total_frames}, total_episodes={total_episodes}, total_videos={total_videos}")


def recompute_stats_v21(repo_id: str, num_workers: int = 8, video_backend="pyav"):
    # è®¡ç®— meta ä¿¡æ¯ï¼Œ æ›´æ–° info.json
    basePath = Path("~/.cache/huggingface/lerobot/" + repo_id ).expanduser()  # è¦å±•å¼€`~`
    episodes_path = basePath / EPISODES_PATH
    videos_path = basePath / "videos"
    episodes_stats_path = basePath /EPISODES_STATS_PATH

 
    total_frames = get_total_frames(episodes_path)
    total_episodes = get_total_episodes(episodes_path)
    total_videos = get_total_videos(videos_path)

    update_info_json(basePath, total_frames, total_episodes, total_videos)

    # é‡æ–°è®¡ç®— episodes_stats.jsonl (info.json å¾—æ˜¯æ­£ç¡®çš„å…ˆ)
    
    # å¦‚æœ episodes_stats.jsonl æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°±åˆ›å»ºä¸€ä¸ªç©ºæ–‡ä»¶(å¦åˆ™æ— æ³•åŠ è½½æ•°æ®é›†)
    if not episodes_stats_path.exists():
        episodes_stats_path.parent.mkdir(parents=True, exist_ok=True)  
        episodes_stats_path.touch()

    dataset = LeRobotDataset(
        repo_id=repo_id,
        video_backend= video_backend,
        force_cache_sync=False,
    )
    print(f"ğŸ“¦ æ•°æ®é›†åŠ è½½æˆåŠŸï¼š{repo_id}")

    remove_old_stats(dataset)
    generate_new_stats(dataset, num_workers)




if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="é‡æ–°è®¡ç®— LeRobot v2.1 æ•°æ®é›†çš„ç»Ÿè®¡ä¿¡æ¯å’Œ meta ä¿¡æ¯")

    parser.add_argument("--repo_id", type=str, required=True, help="æœ¬åœ°æ•°æ®é›†è·¯å¾„")
    parser.add_argument("--num-workers", type=int, default=4, help="å¹¶è¡Œè®¡ç®—çš„çº¿ç¨‹æ•°")
    parser.add_argument("--video-backend", type=str, default="pyav", help="è§†é¢‘å¤„ç†åç«¯ï¼ˆpyav æˆ– ffmpegï¼‰")

    args = parser.parse_args()

    recompute_stats_v21(
        repo_id=args.repo_id,
        num_workers=args.num_workers,
        video_backend=args.video_backend,
    )


"""
ä¾‹å­ï¼š
    python utils/recompute_stats.py --repo_id ${HF_USER}/${TASK_NAME}
"""